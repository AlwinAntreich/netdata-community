{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalies collector - step by step tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/andrewm4894/netdata-community/blob/main/netdata-agent-api/netdata-pandas/anomalies_collector_tutorial.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk through, step by step, a worked example of how the [netdata anomalies collector](https://github.com/andrewm4894/netdata/tree/anomalies-collector/collectors/python.d.plugin/anomalies) works under the hood. \n",
    "\n",
    "**Note**: you can click the \"Open in Colab\" button above to open this notebook in [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true) where you can just get going with it without having to set up python enviornments or any messy stuff like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line to install required packages if needed.\n",
    "#!pip install netdata-pandas==0.0.28 numba==0.50.1 scikit-learn==0.23.2 pyod==0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main concepts central to what the anomalies collector does:\n",
    "\n",
    "- **featurization**: This is how we take the raw data for each chart and preprocess it into a feature representation or \"[feature vector](https://en.wikipedia.org/wiki/Feature_(machine_learning)\" used by the model. A simple way to think of this is that we just take each row of data and add some extra columns to encode some additional information, like for example a smoothed average of the last `lags_n` values for each dimension on the chart so the model can have some knowledge of the recent past beyond just the latest raw values of the dimensions on the chart. \n",
    "- **training**: A function to take our \"featurized\" training data and train our models, one for each chart. This function will do slighly different things depending on what model you use but in a broad sense its job is to train a model that gets good at 'reconstructing' the featurized training data from itself. Some other models might take a slightly different approach and instead of trying to reconstruct the training data will learn a function that can give you a measure of suprise for each feature vector without explicitly trying to reconstruct the data it is trained on. For the purpose of what we are doing this is largely abscracted away by the API of the PyOD library, such that as a user we can easily swith between various models and still have broadly the same inputs and outputs.     \n",
    "- **prediction**: Each trained model then has a predict() function that we can use by passing in a new feature vector and getting back an anomaly probability and anomaly flag from the trained model. This is the part where we actually use the trained model and as new data arrives we basically ask it - \"how unusual does this feature vector look to you?\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netdata_pandas.data import get_data, get_allmetrics\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "\n",
    "def make_features(df, lags_n, diffs_n, smooth_n):\n",
    "    \"\"\"Given a pandas dataframe preprocess it to take differences, add smoothing, and lags as specified. \n",
    "    \"\"\"\n",
    "    if diffs_n >= 1:\n",
    "        # take differences\n",
    "        df = df.diff(diffs_n).dropna()\n",
    "    if smooth_n >= 2:\n",
    "        # apply a rolling average to smooth out the data a bit\n",
    "        df = df.rolling(smooth_n).mean().dropna()\n",
    "    if lags_n >= 1:\n",
    "        # for each dimension add a new columns for each of lags_n lags of the differenced and smoothed values for that dimension\n",
    "        df_columns_new = [f'{col}_lag{n}' for n in range(lags_n+1) for col in df.columns]\n",
    "        df = pd.concat([df.shift(n) for n in range(lags_n + 1)], axis=1).dropna()\n",
    "        df.columns = df_columns_new\n",
    "    # sort columns to have lagged values next to each other for clarity when looking at the feature vectors\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs & configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we will define all the inputs we will use in this tutorial. Feel free to play with them once you are familiar with how it all hangs together.\n",
    "\n",
    "Below you will see that the paramater values map to a subset of the inputs (the most important ones that will help explain whats going on) required as part of the [`anomalies.conf`](https://github.com/andrewm4894/netdata/blob/anomalies-collector/collectors/python.d.plugin/anomalies/anomalies.conf) configuration for the anomalies collector itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "# what host will we use\n",
    "host = 'london.my-netdata.io'\n",
    "# for this tutorial we will just use two charts, and so two models\n",
    "charts_in_scope = ['system.cpu', 'system.load', 'system.net', 'system.io']\n",
    "# what model from PyOD will we use under the hood\n",
    "model = 'pca'\n",
    "# how many seconds of data will we train our models on\n",
    "train_n_secs = 14400\n",
    "# what contamination rate will we use, see some discussion here to understand this one more: https://github.com/yzhao062/pyod/issues/144\n",
    "contamination = 0.001\n",
    "# if we want to ignore a recent window of data when training the model we can use this\n",
    "offset_n_secs = 0\n",
    "# how many lags to include in our feature vector\n",
    "lags_n = 5\n",
    "# how much smoothing to apply in our feature vector\n",
    "smooth_n = 3\n",
    "# if we want to do everything in terms of differences then we set diffs_n=1\n",
    "diffs_n = 1\n",
    "# for purpose of this turorial how many prediction steps will we take once we have a trained model\n",
    "n_prediction_steps = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will initialize a PyOD model for each chart in `charts_in_scope`. Each model in PyOD will have various different input paramaters that a user can play with, we will tend to use the defaults and overide them sometimes with ones we have picked based on what we know about the task we are working on. Generally these model paramaters, apart from contamination, are hardcoded into the anomalies collector based on our internal research as we developed the collector, you can see this in the [collector code here](https://github.com/andrewm4894/netdata/blob/anomalies-collector/collectors/python.d.plugin/anomalies/anomalies.chart.py#L77).\n",
    "\n",
    "In the cell below we have added a comment for the source and API reference of each model from PyOD so you can take a look and read more about each one.\n",
    "\n",
    "By default the anomalies collector uses the `PCA` model, primarially this is because the pca model gives a good combination of being able to capture and model flexible patterns in the data while also being computationally fast since under the hood it is using the well researched, optimized and understood [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition) algorithim to decompose our featurized data and project it onto a lower dimensional space. At a high level, when we see new data that is in a strange or unexpected part of this lower dimensional space then this is symptomatic of some anomalous data and so will get a higher anomaly score. \n",
    "\n",
    "- api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca\n",
    "- source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/pca.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model for each chart\n",
    "if model == 'pca':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/pca.html\n",
    "    models = {c: PCA(contamination=contamination, n_components=2, n_selected_components=2) for c in charts_in_scope}\n",
    "elif model == 'hbos':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/hbos.html\n",
    "    models = {c: HBOS(contamination=contamination) for c in charts_in_scope}\n",
    "elif model == 'cblof':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/cblof.html\n",
    "    models = {c: CBLOF(contamination=contamination, n_clusters=4) for c in charts_in_scope}\n",
    "elif model == 'iforest':\n",
    "    # api: https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest\n",
    "    # source: https://pyod.readthedocs.io/en/latest/_modules/pyod/models/iforest.html\n",
    "    models = {c: IForest(contamination=contamination, n_estimators=50, bootstrap=True, behaviour='new') for c in charts_in_scope}\n",
    "else:\n",
    "    # we used the HBOS as default as it is both fast and robust to many different types of data and has proven in internal development \n",
    "    # to have less failure modes then some other models given the wide variaty of data we are expecting to be thrown at it\n",
    "    models = {c: HBOS(contamination=contamination) for c in charts_in_scope}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is get our raw training data for each chart we want to build a model for.\n",
    "\n",
    "To get the data we will make use of the [netdata-pandas](https://github.com/netdata/netdata-pandas) library we have built to make multiple asynchronous calls to the [Netdata REST API](https://learn.netdata.cloud/docs/agent/web/api) and basically wrangle the results into a nice [Pandas](https://pandas.pydata.org/) [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14399 entries, 1603872875 to 1603887273\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   system.cpu|guest       14399 non-null  float32\n",
      " 1   system.cpu|guest_nice  14399 non-null  float32\n",
      " 2   system.cpu|iowait      14399 non-null  float32\n",
      " 3   system.cpu|irq         14399 non-null  float32\n",
      " 4   system.cpu|nice        14399 non-null  float32\n",
      " 5   system.cpu|softirq     14399 non-null  float32\n",
      " 6   system.cpu|steal       14399 non-null  float32\n",
      " 7   system.cpu|system      14399 non-null  float32\n",
      " 8   system.cpu|user        14399 non-null  float32\n",
      " 9   system.io|in           14399 non-null  float32\n",
      " 10  system.io|out          14399 non-null  float32\n",
      " 11  system.load|load1      14399 non-null  float32\n",
      " 12  system.load|load15     14399 non-null  float32\n",
      " 13  system.load|load5      14399 non-null  float32\n",
      " 14  system.net|received    14399 non-null  float32\n",
      " 15  system.net|sent        14399 non-null  float32\n",
      "dtypes: float32(16)\n",
      "memory usage: 1012.4 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|guest</th>\n",
       "      <th>system.cpu|guest_nice</th>\n",
       "      <th>system.cpu|iowait</th>\n",
       "      <th>system.cpu|irq</th>\n",
       "      <th>system.cpu|nice</th>\n",
       "      <th>system.cpu|softirq</th>\n",
       "      <th>system.cpu|steal</th>\n",
       "      <th>system.cpu|system</th>\n",
       "      <th>system.cpu|user</th>\n",
       "      <th>system.io|in</th>\n",
       "      <th>system.io|out</th>\n",
       "      <th>system.load|load1</th>\n",
       "      <th>system.load|load15</th>\n",
       "      <th>system.load|load5</th>\n",
       "      <th>system.net|received</th>\n",
       "      <th>system.net|sent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603872875</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501253</td>\n",
       "      <td>0.501253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>58.235050</td>\n",
       "      <td>-55.117802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872876</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755668</td>\n",
       "      <td>0.251889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>58.105171</td>\n",
       "      <td>-156.052414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872877</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755668</td>\n",
       "      <td>0.755668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>199.398605</td>\n",
       "      <td>-99.251968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872878</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.501253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.289742</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>155.327377</td>\n",
       "      <td>-78.049698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503778</td>\n",
       "      <td>1.007557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-23.710260</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>113.740067</td>\n",
       "      <td>-110.700722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|guest  system.cpu|guest_nice  system.cpu|iowait  \\\n",
       "time_idx                                                                 \n",
       "1603872875               0.0                    0.0                0.0   \n",
       "1603872876               0.0                    0.0                0.0   \n",
       "1603872877               0.0                    0.0                0.0   \n",
       "1603872878               0.0                    0.0                0.0   \n",
       "1603872879               0.0                    0.0                0.0   \n",
       "\n",
       "            system.cpu|irq  system.cpu|nice  system.cpu|softirq  \\\n",
       "time_idx                                                          \n",
       "1603872875             0.0              0.0            0.000000   \n",
       "1603872876             0.0              0.0            0.000000   \n",
       "1603872877             0.0              0.0            0.000000   \n",
       "1603872878             0.0              0.0            0.250627   \n",
       "1603872879             0.0              0.0            0.251889   \n",
       "\n",
       "            system.cpu|steal  system.cpu|system  system.cpu|user  \\\n",
       "time_idx                                                           \n",
       "1603872875               0.0           0.501253         0.501253   \n",
       "1603872876               0.0           0.755668         0.251889   \n",
       "1603872877               0.0           0.755668         0.755668   \n",
       "1603872878               0.0           0.751880         0.501253   \n",
       "1603872879               0.0           0.503778         1.007557   \n",
       "\n",
       "            system.io|in  system.io|out  system.load|load1  \\\n",
       "time_idx                                                     \n",
       "1603872875           0.0       0.000000               0.05   \n",
       "1603872876           0.0       0.000000               0.05   \n",
       "1603872877           0.0       0.000000               0.05   \n",
       "1603872878           0.0     -48.289742               0.05   \n",
       "1603872879           0.0     -23.710260               0.05   \n",
       "\n",
       "            system.load|load15  system.load|load5  system.net|received  \\\n",
       "time_idx                                                                 \n",
       "1603872875                0.03               0.07            58.235050   \n",
       "1603872876                0.03               0.07            58.105171   \n",
       "1603872877                0.03               0.07           199.398605   \n",
       "1603872878                0.03               0.07           155.327377   \n",
       "1603872879                0.03               0.07           113.740067   \n",
       "\n",
       "            system.net|sent  \n",
       "time_idx                     \n",
       "1603872875       -55.117802  \n",
       "1603872876      -156.052414  \n",
       "1603872877       -99.251968  \n",
       "1603872878       -78.049698  \n",
       "1603872879      -110.700722  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the window for the training data to pull\n",
    "before = int(datetime.now().timestamp()) - offset_n_secs\n",
    "after =  before - train_n_secs\n",
    "\n",
    "# get the training data\n",
    "df_train = get_data(hosts=host, charts=charts_in_scope, after=after, before=before, sort_cols=True, numeric_only=True, float_size='float32')\n",
    "print(df_train.info())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see our raw training data is just a pandas `DataFrame` with a timestamp index and a column for each dimension from our `charts_in_scope` list.\n",
    "\n",
    "**Note**: The [netdata-pandas](https://github.com/netdata/netdata-pandas) default naming convention for columns is \"chart.name|dimension.name\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train our model we will first do some preprocessing to the raw data to create a \"feature vector\" to try and encode a more flexible and powerful representation for the model to work with as opposed to just looking at the most recently observed values in isolation. \n",
    "\n",
    "This is the \"featurization\" we mentioned at the begining of the notebook. The idea here is to give the model some extra information so that it may spot more complex and interesting anomalies as opposed to just spikes where one metric is a very high or very low value.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14391, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|guest_lag0</th>\n",
       "      <th>system.cpu|guest_lag1</th>\n",
       "      <th>system.cpu|guest_lag2</th>\n",
       "      <th>system.cpu|guest_lag3</th>\n",
       "      <th>system.cpu|guest_lag4</th>\n",
       "      <th>system.cpu|guest_lag5</th>\n",
       "      <th>system.cpu|guest_nice_lag0</th>\n",
       "      <th>system.cpu|guest_nice_lag1</th>\n",
       "      <th>system.cpu|guest_nice_lag2</th>\n",
       "      <th>system.cpu|guest_nice_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>system.net|received_lag2</th>\n",
       "      <th>system.net|received_lag3</th>\n",
       "      <th>system.net|received_lag4</th>\n",
       "      <th>system.net|received_lag5</th>\n",
       "      <th>system.net|sent_lag0</th>\n",
       "      <th>system.net|sent_lag1</th>\n",
       "      <th>system.net|sent_lag2</th>\n",
       "      <th>system.net|sent_lag3</th>\n",
       "      <th>system.net|sent_lag4</th>\n",
       "      <th>system.net|sent_lag5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603872883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.064599</td>\n",
       "      <td>-31.864746</td>\n",
       "      <td>18.544963</td>\n",
       "      <td>32.364106</td>\n",
       "      <td>23.657443</td>\n",
       "      <td>23.487494</td>\n",
       "      <td>6.468403</td>\n",
       "      <td>-3.333796</td>\n",
       "      <td>15.117231</td>\n",
       "      <td>-7.643967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872884</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.220114</td>\n",
       "      <td>-33.064599</td>\n",
       "      <td>-31.864746</td>\n",
       "      <td>18.544963</td>\n",
       "      <td>-29.390568</td>\n",
       "      <td>23.657443</td>\n",
       "      <td>23.487494</td>\n",
       "      <td>6.468403</td>\n",
       "      <td>-3.333796</td>\n",
       "      <td>15.117231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.987481</td>\n",
       "      <td>29.220114</td>\n",
       "      <td>-33.064599</td>\n",
       "      <td>-31.864746</td>\n",
       "      <td>-17.817933</td>\n",
       "      <td>-29.390568</td>\n",
       "      <td>23.657443</td>\n",
       "      <td>23.487494</td>\n",
       "      <td>6.468403</td>\n",
       "      <td>-3.333796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.315852</td>\n",
       "      <td>2.987481</td>\n",
       "      <td>29.220114</td>\n",
       "      <td>-33.064599</td>\n",
       "      <td>4.513982</td>\n",
       "      <td>-17.817933</td>\n",
       "      <td>-29.390568</td>\n",
       "      <td>23.657443</td>\n",
       "      <td>23.487494</td>\n",
       "      <td>6.468403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.601482</td>\n",
       "      <td>-2.315852</td>\n",
       "      <td>2.987481</td>\n",
       "      <td>29.220114</td>\n",
       "      <td>37.946377</td>\n",
       "      <td>4.513982</td>\n",
       "      <td>-17.817933</td>\n",
       "      <td>-29.390568</td>\n",
       "      <td>23.657443</td>\n",
       "      <td>23.487494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|guest_lag0  system.cpu|guest_lag1  \\\n",
       "time_idx                                                   \n",
       "1603872883                    0.0                    0.0   \n",
       "1603872884                    0.0                    0.0   \n",
       "1603872885                    0.0                    0.0   \n",
       "1603872886                    0.0                    0.0   \n",
       "1603872887                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag2  system.cpu|guest_lag3  \\\n",
       "time_idx                                                   \n",
       "1603872883                    0.0                    0.0   \n",
       "1603872884                    0.0                    0.0   \n",
       "1603872885                    0.0                    0.0   \n",
       "1603872886                    0.0                    0.0   \n",
       "1603872887                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag4  system.cpu|guest_lag5  \\\n",
       "time_idx                                                   \n",
       "1603872883                    0.0                    0.0   \n",
       "1603872884                    0.0                    0.0   \n",
       "1603872885                    0.0                    0.0   \n",
       "1603872886                    0.0                    0.0   \n",
       "1603872887                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag0  system.cpu|guest_nice_lag1  \\\n",
       "time_idx                                                             \n",
       "1603872883                         0.0                         0.0   \n",
       "1603872884                         0.0                         0.0   \n",
       "1603872885                         0.0                         0.0   \n",
       "1603872886                         0.0                         0.0   \n",
       "1603872887                         0.0                         0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag2  system.cpu|guest_nice_lag3  ...  \\\n",
       "time_idx                                                            ...   \n",
       "1603872883                         0.0                         0.0  ...   \n",
       "1603872884                         0.0                         0.0  ...   \n",
       "1603872885                         0.0                         0.0  ...   \n",
       "1603872886                         0.0                         0.0  ...   \n",
       "1603872887                         0.0                         0.0  ...   \n",
       "\n",
       "            system.net|received_lag2  system.net|received_lag3  \\\n",
       "time_idx                                                         \n",
       "1603872883                -33.064599                -31.864746   \n",
       "1603872884                 29.220114                -33.064599   \n",
       "1603872885                  2.987481                 29.220114   \n",
       "1603872886                 -2.315852                  2.987481   \n",
       "1603872887                -50.601482                 -2.315852   \n",
       "\n",
       "            system.net|received_lag4  system.net|received_lag5  \\\n",
       "time_idx                                                         \n",
       "1603872883                 18.544963                 32.364106   \n",
       "1603872884                -31.864746                 18.544963   \n",
       "1603872885                -33.064599                -31.864746   \n",
       "1603872886                 29.220114                -33.064599   \n",
       "1603872887                  2.987481                 29.220114   \n",
       "\n",
       "            system.net|sent_lag0  system.net|sent_lag1  system.net|sent_lag2  \\\n",
       "time_idx                                                                       \n",
       "1603872883             23.657443             23.487494              6.468403   \n",
       "1603872884            -29.390568             23.657443             23.487494   \n",
       "1603872885            -17.817933            -29.390568             23.657443   \n",
       "1603872886              4.513982            -17.817933            -29.390568   \n",
       "1603872887             37.946377              4.513982            -17.817933   \n",
       "\n",
       "            system.net|sent_lag3  system.net|sent_lag4  system.net|sent_lag5  \n",
       "time_idx                                                                      \n",
       "1603872883             -3.333796             15.117231             -7.643967  \n",
       "1603872884              6.468403             -3.333796             15.117231  \n",
       "1603872885             23.487494              6.468403             -3.333796  \n",
       "1603872886             23.657443             23.487494              6.468403  \n",
       "1603872887            -29.390568             23.657443             23.487494  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets preprocess or \"featurize\" our raw data\n",
    "df_train_processed = make_features(df_train, lags_n, diffs_n, smooth_n)\n",
    "\n",
    "# print out the shape of our featurized data\n",
    "print(df_train_processed.shape)\n",
    "df_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below few cells will explore a little what we have just done to try and make the ideas of preprocessing aka \"featurization\" aka \"feature vector\" a little clearer.\n",
    "\n",
    "Terms like \"featurization\" and \"feature vector\" are often used to sound fancy, but in reality its typically just as simple as adding additional columns to each row of your data, where those new columns have numbers in them that represent something about your data that you want to make available to the model. \n",
    "\n",
    "So in our case adding lagged values of each smoothed and differenced dimension, is basically a design choice we make whereby we are telling the model we want it to consider `lags_n` recent values as opposed to just the latest observed dimensions. We do this because there are many [different types of anomalies](https://andrewm4894.com/2020/10/19/different-types-of-time-series-anomalies/) we want to try and be able to spot, so making a small snippet of recent data for each dimension available to the model gives us the ability to capture more complex anomaly patterns that might happen.\n",
    "\n",
    "If we were to just train the model on the most recent values for each dimension the best we could reasonably hope for it to capture would be anomalies where one or more dimension takes an unusually high or low value for one time step. This is essentially not that much better then a traditional approach using z-scores. (If you are interested in comparing the two we actually also have a [zscores collector](https://github.com/andrewm4894/netdata/tree/zscores-collector/collectors/python.d.plugin/zscores) on the way too, if you would like to just start simple or cannot install the ML Python libraries the anomalies collector depends on for example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape is (14399, 16)\n",
      "df_train_processed is (14391, 96)\n",
      "make_features has added 80 new columns, one for each lags_n (16*5=80)\n"
     ]
    }
   ],
   "source": [
    "# Lets look at how the shape of our data has changed due to preprocessing\n",
    "print(f'df_train shape is {df_train.shape}')\n",
    "print(f'df_train_processed is {df_train_processed.shape}')\n",
    "n_cols_added = len(df_train_processed.columns)-len(df_train.columns)\n",
    "print(f'make_features has added {n_cols_added} new columns, one for each lags_n ({df_train.shape[1]}*{lags_n}={n_cols_added})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as you can see from the above output, our featurization has added a new column for each `lags_n` specified. And we have also lost a few rows due to `smooth_n` and `diffs_n`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be super clear lets look at the first few rows of training data for a specific metric before and after preprocessing. \n",
    "\n",
    "**Note**: Look at the last `time_idx` to see how the featurization works for a specific timestamp of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603872875</th>\n",
       "      <td>0.501253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872876</th>\n",
       "      <td>0.251889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872877</th>\n",
       "      <td>0.755668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872878</th>\n",
       "      <td>0.501253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872879</th>\n",
       "      <td>1.007557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872880</th>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872881</th>\n",
       "      <td>0.503778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872882</th>\n",
       "      <td>0.505050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872883</th>\n",
       "      <td>1.503759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872884</th>\n",
       "      <td>1.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872885</th>\n",
       "      <td>0.502513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603872886</th>\n",
       "      <td>0.753769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|user\n",
       "time_idx                   \n",
       "1603872875         0.501253\n",
       "1603872876         0.251889\n",
       "1603872877         0.755668\n",
       "1603872878         0.501253\n",
       "1603872879         1.007557\n",
       "1603872880         0.757576\n",
       "1603872881         0.503778\n",
       "1603872882         0.505050\n",
       "1603872883         1.503759\n",
       "1603872884         1.002506\n",
       "1603872885         0.502513\n",
       "1603872886         0.753769"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = 'system.cpu|user'\n",
    "print('raw data')\n",
    "display(df_train[df_train.columns[df_train.columns.str.startswith(metric)]].head(3 + lags_n + smooth_n + diffs_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurized data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|user_lag0</th>\n",
       "      <th>system.cpu|user_lag1</th>\n",
       "      <th>system.cpu|user_lag2</th>\n",
       "      <th>system.cpu|user_lag3</th>\n",
       "      <th>system.cpu|user_lag4</th>\n",
       "      <th>system.cpu|user_lag5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603872883</th>\n",
       "      <td>0.248728</td>\n",
       "      <td>-0.167502</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.251889</td>\n",
       "      <td>9.934107e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|user_lag0  system.cpu|user_lag1  system.cpu|user_lag2  \\\n",
       "time_idx                                                                       \n",
       "1603872883              0.248728             -0.167502              0.000842   \n",
       "\n",
       "            system.cpu|user_lag3  system.cpu|user_lag4  system.cpu|user_lag5  \n",
       "time_idx                                                                      \n",
       "1603872883              0.000636              0.251889          9.934107e-09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('featurized data')\n",
    "display(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(metric)]].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manualy calculated\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603872886</th>\n",
       "      <td>-0.249997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|user\n",
       "time_idx                   \n",
       "1603872886        -0.249997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('manualy calculated')\n",
    "# here we take differences and smooth values for one specific dimension's latest value e.g. lag0\n",
    "# the same calculation is donw for each lag, obiously just in a shifted manner\n",
    "display(\n",
    "    df_train[df_train.columns[df_train.columns.str.startswith(metric)]]\\\n",
    "    .diff(diffs_n).dropna()\\\n",
    "    .rolling(smooth_n).mean()\\\n",
    "    .head(2 + lags_n + smooth_n + diffs_n).tail(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see how one raw metric value is now being preprocessed to be a vector of `lags_n` differenced and smoothed values. It is this matrix of smoothed differences that the model will use for both training and during a predict step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example, if a chart has 3 dimensions and we have set `lags_n` to be 5 then our featurized 'matrix' of numbers will be a 3*(1+5) matrix. In reality this matrix is just flattened into a feature vector of 3 * (1+5) = 18 floating point values. The cell below shows this for the `system.load` chart as that is an example with 3 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 18)\n",
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.00333333 -0.00333333 -0.00333333  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# lets look at our first feature vector for the 'system.load' model \n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith('system.load')]].head(1).shape)\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith('system.load')]].head(1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our preprocessed training data we will train a model for each chart using our featurized data that represents each time step for each chart as a differenced, smoothed, and lagged matrix for each chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model for system.cpu using X_train of (14391, 54)\n",
      "train model for system.load using X_train of (14391, 18)\n",
      "train model for system.net using X_train of (14391, 12)\n",
      "train model for system.io using X_train of (14391, 12)\n"
     ]
    }
   ],
   "source": [
    "# loop over each chart in scope and train a model for each\n",
    "for chart in charts_in_scope:\n",
    "    # pull out the columns relating to the chart based on what thier name startswith and put it into a numpy array of values\n",
    "    X_train = df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(chart)]].values\n",
    "    print(f'train model for {chart} using X_train of {X_train.shape}')\n",
    "    # call the fit() method on each initialized model and pass it the full numpy array of our featurized training data\n",
    "    models[chart] = models[chart].fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have now trained our models, one for each chart based on our preprocessed training data. To be concrete we will look at some example obvervations our model has been trained on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp=1603872883\n",
      "feature vector for 0th training observation for system.cpu model:\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -8.41750999e-02 -8.39630663e-02\n",
      " -8.35421979e-02  8.41750999e-02  8.39630663e-02  8.35421979e-02\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  2.49360780e-01  4.24067179e-04\n",
      " -8.27004711e-02 -8.35390091e-02 -8.39630763e-02  8.35421880e-02\n",
      "  2.48727858e-01 -1.67502065e-01  8.41716925e-04  6.36100769e-04\n",
      "  2.51889169e-01  9.93410746e-09]\n"
     ]
    }
   ],
   "source": [
    "# lets look at the first matrix or \"feature vector\" for our first chart for out first model\n",
    "obs_n = 0\n",
    "model_n = 0\n",
    "print(f'timestamp={df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].index[obs_n]}')\n",
    "print(f'feature vector for {obs_n}th training observation for {charts_in_scope[model_n]} model:')\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].values[obs_n]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp=1603872884\n",
      "feature vector for 1th training observation for system.cpu model:\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.0841751  -0.08396307 -0.0835422   0.0841751   0.08396307\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.00084172  0.24936078  0.00042407 -0.08270047 -0.08353901 -0.08396308\n",
      "  0.16624266  0.24872786 -0.16750207  0.00084172  0.0006361   0.25188917]\n"
     ]
    }
   ],
   "source": [
    "# and the next one\n",
    "obs_n = 1\n",
    "model_n = 0\n",
    "print(f'timestamp={df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].index[obs_n]}')\n",
    "print(f'feature vector for {obs_n}th training observation for {charts_in_scope[model_n]} model:')\n",
    "print(df_train_processed[df_train_processed.columns[df_train_processed.columns.str.startswith(charts_in_scope[model_n])]].values[obs_n]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look close enough at the above two cells you will see the same values be shifted for each lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each matrix of numbers above is the representation we give to our model of each timestep. This is how the model views each chart - a matrix (or \"feature vector\" if you want to sound fancy) of floating point numbers encoding some differenced and smoothed information about the last `lags_n` observations for each dimension in the specific chart we are modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Within the anomalies collector, at some regular interval, as defined by `train_every_n` in the `anomalies.conf` file, we will repeat the above training step to essentially retrain all models on the most recent window of available training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pediction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our trained models for each chart we can use them in looking at incoming obsevarions and 'ask' the trained models how 'unusual' it thinks they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we now have 10 recent preprocessed feature vectors to predict on.\n"
     ]
    }
   ],
   "source": [
    "# define a empty dataframe we can store enough recent data into to generate our feature vector for recent data on\n",
    "df_recent = pd.DataFrame()\n",
    "times = []\n",
    "\n",
    "# simulate n_prediction_steps of getting latest data, making feature vecotr and getting predicitons\n",
    "for prediction_step in range(n_prediction_steps):\n",
    "    time.sleep(1)\n",
    "    df_latest = get_allmetrics(host=host, charts=charts_in_scope, wide=True)[df_train.columns]\n",
    "    df_latest['time_idx'] = int(time.time())\n",
    "    df_latest = df_latest.set_index('time_idx')\n",
    "    # just keep enough recent data to generate each feature vector\n",
    "    df_recent = df_recent.append(df_latest).tail((lags_n + smooth_n + diffs_n) * 2)\n",
    "    \n",
    "    # now lets featurize our recent data to be able to get predictions from the model for each observation\n",
    "    df_predict_processed = make_features(df_recent, lags_n, diffs_n, smooth_n)\n",
    "\n",
    "print(f'we now have {df_predict_processed.shape[0]} recent preprocessed feature vectors to predict on.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 96)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.cpu|guest_lag0</th>\n",
       "      <th>system.cpu|guest_lag1</th>\n",
       "      <th>system.cpu|guest_lag2</th>\n",
       "      <th>system.cpu|guest_lag3</th>\n",
       "      <th>system.cpu|guest_lag4</th>\n",
       "      <th>system.cpu|guest_lag5</th>\n",
       "      <th>system.cpu|guest_nice_lag0</th>\n",
       "      <th>system.cpu|guest_nice_lag1</th>\n",
       "      <th>system.cpu|guest_nice_lag2</th>\n",
       "      <th>system.cpu|guest_nice_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>system.net|received_lag2</th>\n",
       "      <th>system.net|received_lag3</th>\n",
       "      <th>system.net|received_lag4</th>\n",
       "      <th>system.net|received_lag5</th>\n",
       "      <th>system.net|sent_lag0</th>\n",
       "      <th>system.net|sent_lag1</th>\n",
       "      <th>system.net|sent_lag2</th>\n",
       "      <th>system.net|sent_lag3</th>\n",
       "      <th>system.net|sent_lag4</th>\n",
       "      <th>system.net|sent_lag5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1603887288</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.067934</td>\n",
       "      <td>24.261251</td>\n",
       "      <td>43.957575</td>\n",
       "      <td>-71.901983</td>\n",
       "      <td>44.712670</td>\n",
       "      <td>-30.459500</td>\n",
       "      <td>-28.263083</td>\n",
       "      <td>-34.664116</td>\n",
       "      <td>-38.637143</td>\n",
       "      <td>33.655889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603887289</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-45.323688</td>\n",
       "      <td>4.067934</td>\n",
       "      <td>24.261251</td>\n",
       "      <td>43.957575</td>\n",
       "      <td>40.852385</td>\n",
       "      <td>44.712670</td>\n",
       "      <td>-30.459500</td>\n",
       "      <td>-28.263083</td>\n",
       "      <td>-34.664116</td>\n",
       "      <td>-38.637143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603887290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.951936</td>\n",
       "      <td>-45.323688</td>\n",
       "      <td>4.067934</td>\n",
       "      <td>24.261251</td>\n",
       "      <td>23.386360</td>\n",
       "      <td>40.852385</td>\n",
       "      <td>44.712670</td>\n",
       "      <td>-30.459500</td>\n",
       "      <td>-28.263083</td>\n",
       "      <td>-34.664116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603887291</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.406867</td>\n",
       "      <td>28.951936</td>\n",
       "      <td>-45.323688</td>\n",
       "      <td>4.067934</td>\n",
       "      <td>-80.917204</td>\n",
       "      <td>23.386360</td>\n",
       "      <td>40.852385</td>\n",
       "      <td>44.712670</td>\n",
       "      <td>-30.459500</td>\n",
       "      <td>-28.263083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603887293</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.052823</td>\n",
       "      <td>27.406867</td>\n",
       "      <td>28.951936</td>\n",
       "      <td>-45.323688</td>\n",
       "      <td>-26.372788</td>\n",
       "      <td>-80.917204</td>\n",
       "      <td>23.386360</td>\n",
       "      <td>40.852385</td>\n",
       "      <td>44.712670</td>\n",
       "      <td>-30.459500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            system.cpu|guest_lag0  system.cpu|guest_lag1  \\\n",
       "time_idx                                                   \n",
       "1603887288                    0.0                    0.0   \n",
       "1603887289                    0.0                    0.0   \n",
       "1603887290                    0.0                    0.0   \n",
       "1603887291                    0.0                    0.0   \n",
       "1603887293                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag2  system.cpu|guest_lag3  \\\n",
       "time_idx                                                   \n",
       "1603887288                    0.0                    0.0   \n",
       "1603887289                    0.0                    0.0   \n",
       "1603887290                    0.0                    0.0   \n",
       "1603887291                    0.0                    0.0   \n",
       "1603887293                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_lag4  system.cpu|guest_lag5  \\\n",
       "time_idx                                                   \n",
       "1603887288                    0.0                    0.0   \n",
       "1603887289                    0.0                    0.0   \n",
       "1603887290                    0.0                    0.0   \n",
       "1603887291                    0.0                    0.0   \n",
       "1603887293                    0.0                    0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag0  system.cpu|guest_nice_lag1  \\\n",
       "time_idx                                                             \n",
       "1603887288                         0.0                         0.0   \n",
       "1603887289                         0.0                         0.0   \n",
       "1603887290                         0.0                         0.0   \n",
       "1603887291                         0.0                         0.0   \n",
       "1603887293                         0.0                         0.0   \n",
       "\n",
       "            system.cpu|guest_nice_lag2  system.cpu|guest_nice_lag3  ...  \\\n",
       "time_idx                                                            ...   \n",
       "1603887288                         0.0                         0.0  ...   \n",
       "1603887289                         0.0                         0.0  ...   \n",
       "1603887290                         0.0                         0.0  ...   \n",
       "1603887291                         0.0                         0.0  ...   \n",
       "1603887293                         0.0                         0.0  ...   \n",
       "\n",
       "            system.net|received_lag2  system.net|received_lag3  \\\n",
       "time_idx                                                         \n",
       "1603887288                  4.067934                 24.261251   \n",
       "1603887289                -45.323688                  4.067934   \n",
       "1603887290                 28.951936                -45.323688   \n",
       "1603887291                 27.406867                 28.951936   \n",
       "1603887293                 -6.052823                 27.406867   \n",
       "\n",
       "            system.net|received_lag4  system.net|received_lag5  \\\n",
       "time_idx                                                         \n",
       "1603887288                 43.957575                -71.901983   \n",
       "1603887289                 24.261251                 43.957575   \n",
       "1603887290                  4.067934                 24.261251   \n",
       "1603887291                -45.323688                  4.067934   \n",
       "1603887293                 28.951936                -45.323688   \n",
       "\n",
       "            system.net|sent_lag0  system.net|sent_lag1  system.net|sent_lag2  \\\n",
       "time_idx                                                                       \n",
       "1603887288             44.712670            -30.459500            -28.263083   \n",
       "1603887289             40.852385             44.712670            -30.459500   \n",
       "1603887290             23.386360             40.852385             44.712670   \n",
       "1603887291            -80.917204             23.386360             40.852385   \n",
       "1603887293            -26.372788            -80.917204             23.386360   \n",
       "\n",
       "            system.net|sent_lag3  system.net|sent_lag4  system.net|sent_lag5  \n",
       "time_idx                                                                      \n",
       "1603887288            -34.664116            -38.637143             33.655889  \n",
       "1603887289            -28.263083            -34.664116            -38.637143  \n",
       "1603887290            -30.459500            -28.263083            -34.664116  \n",
       "1603887291             44.712670            -30.459500            -28.263083  \n",
       "1603887293             40.852385             44.712670            -30.459500  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_predict_processed.shape)\n",
    "df_predict_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above featureized prediction data should be identical in terms of structure and schema to the featurized training data we explored above. This is what is expected by the model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predictions for time 1603887288\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0674, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.068, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0293, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887289\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0723, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0615, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0265, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887290\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.079, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0517, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0215, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887291\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0615, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0767, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0326, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887293\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0618, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0797, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0308, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887294\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0635, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0943, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0261, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887295\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0573, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0873, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0195, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887296\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.061, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0716, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0085, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887297\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0599, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0821, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0156, anomaly_flag=0\n",
      "\n",
      "predictions for time 1603887298\n",
      "\n",
      "model=system.cpu, anomaly_probability=0.0627, anomaly_flag=0\n",
      "model=system.load, anomaly_probability=0.0005, anomaly_flag=0\n",
      "model=system.net, anomaly_probability=0.0691, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=0.0173, anomaly_flag=0\n"
     ]
    }
   ],
   "source": [
    "# for each recent feature vector, get a prediction\n",
    "for time_idx, row in df_predict_processed.iterrows():\n",
    "    \n",
    "    print(f'\\npredictions for time {time_idx}\\n')\n",
    "    \n",
    "    # convert our row into the expected 'flattened' feature vector\n",
    "    df_tmp = row.to_frame().transpose()\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        # pull out relevant array of features for the model in question\n",
    "        X_predict = df_tmp[df_tmp.columns[df_tmp.columns.str.startswith(model)]].values\n",
    "        \n",
    "        # call the predict_proba() and predict() methods on the trained data in order to make a prediction\n",
    "        anomaly_probability = round(models[model].predict_proba(X_predict)[-1][1],4)\n",
    "        anomaly_flag = models[model].predict(X_predict)[-1]\n",
    "        \n",
    "        print(f'model={model}, anomaly_probability={anomaly_probability}, anomaly_flag={anomaly_flag}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above will probably see generally low `anomaly_probability` values assuming nothing has blown up on the host you used between the time you ran the training cells above and the predictions above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just do one last little thing to try show what is going on here and why we put so much effort and focus into the featurization above.\n",
    "\n",
    "We will take one of the last feature vectors we predicted on for each model, randomly shuffle the values around so as to make an unusual looking observations, and see what sort of an anomaly probability that gives us. (hint: it should be higher then those above :) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=system.cpu, anomaly_probability=1.0, anomaly_flag=1\n",
      "model=system.load, anomaly_probability=1.0, anomaly_flag=1\n",
      "model=system.net, anomaly_probability=0.0, anomaly_flag=0\n",
      "model=system.io, anomaly_probability=1.0, anomaly_flag=1\n"
     ]
    }
   ],
   "source": [
    "df_predict_shuffled = df_predict_processed.tail(1).transpose().sample(frac=1).transpose()\n",
    "df_predict_shuffled.columns = df_predict_processed.columns # rename things to really shuffle things\n",
    "for model in models:\n",
    "        X_predict = df_predict_shuffled[df_predict_shuffled.columns[df_predict_shuffled.columns.str.startswith(model)]].values\n",
    "        anomaly_probability = round(models[model].predict_proba(X_predict)[-1][1],4)\n",
    "        anomaly_flag = models[model].predict(X_predict)[-1]\n",
    "        print(f'model={model}, anomaly_probability={anomaly_probability}, anomaly_flag={anomaly_flag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what _is_ the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try and lift the lid a little on what the model actually is and how it is calculating anomaly probabilities lets take a look at one trained model and what it actually is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model for chart system.cpu:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'contamination': 0.001,\n",
       " 'n_components': 2,\n",
       " 'n_selected_components': 2,\n",
       " 'copy': True,\n",
       " 'whiten': False,\n",
       " 'svd_solver': 'auto',\n",
       " 'tol': 0.0,\n",
       " 'iterated_power': 'auto',\n",
       " 'random_state': None,\n",
       " 'weighted': True,\n",
       " 'standardization': True,\n",
       " '_classes': 2,\n",
       " 'scaler_': StandardScaler(),\n",
       " 'detector_': PCA(n_components=2),\n",
       " 'n_components_': 2,\n",
       " 'components_': array([[ 4.08292445e-18,  9.21720327e-19,  1.78582782e-18,\n",
       "          1.46173196e-19, -5.87271463e-19, -4.31308482e-18,\n",
       "          7.24701690e-19, -5.05469846e-19, -1.07446078e-19,\n",
       "         -1.15569631e-19, -1.36097217e-20, -0.00000000e+00,\n",
       "         -3.12382980e-03,  6.81363698e-02,  3.53673187e-02,\n",
       "         -1.63879621e-02, -8.26808793e-02, -2.63260556e-02,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -6.59145320e-02, -2.79651279e-03,  6.38560992e-02,\n",
       "          6.21802327e-02,  1.03119413e-03, -6.56210039e-02,\n",
       "         -2.09947413e-01, -2.35672553e-02,  1.92372628e-01,\n",
       "          2.16093227e-01,  1.35829095e-02, -1.69358977e-01,\n",
       "         -3.18406129e-01, -7.76170078e-02,  2.67329495e-01,\n",
       "          3.22801651e-01,  4.79081405e-02, -2.82958008e-01,\n",
       "         -3.56087885e-01, -1.97583550e-02,  3.13725273e-01,\n",
       "          3.16789502e-01, -2.95869141e-02, -3.46720087e-01],\n",
       "        [ 6.23314539e-19,  5.95136015e-18,  7.61456954e-18,\n",
       "          4.17134822e-18, -1.61735263e-18,  1.75115845e-18,\n",
       "         -1.29748751e-18, -2.24749615e-19,  1.03244442e-18,\n",
       "          2.90830285e-19, -1.33383680e-20, -0.00000000e+00,\n",
       "         -4.28785049e-02, -2.94095546e-03,  6.70834870e-02,\n",
       "          4.74915808e-02, -1.28676384e-02, -8.70689760e-02,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -2.73320625e-02, -7.81708668e-02, -2.88796927e-02,\n",
       "          3.57106186e-02,  8.31365221e-02,  3.18530657e-02,\n",
       "         -1.23917873e-01, -2.84302122e-01, -1.62102597e-01,\n",
       "          1.15689331e-01,  2.78517818e-01,  1.61686146e-01,\n",
       "         -9.86071174e-02, -3.56452180e-01, -2.31696141e-01,\n",
       "          1.19281992e-01,  3.65206566e-01,  2.14069791e-01,\n",
       "         -1.20479657e-01, -3.62361447e-01, -1.67495213e-01,\n",
       "          1.66179847e-01,  3.58173053e-01,  1.16292895e-01]]),\n",
       " 'n_selected_components_': 2,\n",
       " 'w_components_': array([0.07239704, 0.06954512]),\n",
       " 'selected_components_': array([[ 4.08292445e-18,  9.21720327e-19,  1.78582782e-18,\n",
       "          1.46173196e-19, -5.87271463e-19, -4.31308482e-18,\n",
       "          7.24701690e-19, -5.05469846e-19, -1.07446078e-19,\n",
       "         -1.15569631e-19, -1.36097217e-20, -0.00000000e+00,\n",
       "         -3.12382980e-03,  6.81363698e-02,  3.53673187e-02,\n",
       "         -1.63879621e-02, -8.26808793e-02, -2.63260556e-02,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -6.59145320e-02, -2.79651279e-03,  6.38560992e-02,\n",
       "          6.21802327e-02,  1.03119413e-03, -6.56210039e-02,\n",
       "         -2.09947413e-01, -2.35672553e-02,  1.92372628e-01,\n",
       "          2.16093227e-01,  1.35829095e-02, -1.69358977e-01,\n",
       "         -3.18406129e-01, -7.76170078e-02,  2.67329495e-01,\n",
       "          3.22801651e-01,  4.79081405e-02, -2.82958008e-01,\n",
       "         -3.56087885e-01, -1.97583550e-02,  3.13725273e-01,\n",
       "          3.16789502e-01, -2.95869141e-02, -3.46720087e-01],\n",
       "        [ 6.23314539e-19,  5.95136015e-18,  7.61456954e-18,\n",
       "          4.17134822e-18, -1.61735263e-18,  1.75115845e-18,\n",
       "         -1.29748751e-18, -2.24749615e-19,  1.03244442e-18,\n",
       "          2.90830285e-19, -1.33383680e-20, -0.00000000e+00,\n",
       "         -4.28785049e-02, -2.94095546e-03,  6.70834870e-02,\n",
       "          4.74915808e-02, -1.28676384e-02, -8.70689760e-02,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         -2.73320625e-02, -7.81708668e-02, -2.88796927e-02,\n",
       "          3.57106186e-02,  8.31365221e-02,  3.18530657e-02,\n",
       "         -1.23917873e-01, -2.84302122e-01, -1.62102597e-01,\n",
       "          1.15689331e-01,  2.78517818e-01,  1.61686146e-01,\n",
       "         -9.86071174e-02, -3.56452180e-01, -2.31696141e-01,\n",
       "          1.19281992e-01,  3.65206566e-01,  2.14069791e-01,\n",
       "         -1.20479657e-01, -3.62361447e-01, -1.67495213e-01,\n",
       "          1.66179847e-01,  3.58173053e-01,  1.16292895e-01]]),\n",
       " 'selected_w_components_': array([0.07239704, 0.06954512]),\n",
       " 'decision_scores_': array([155.35956648, 156.38240478, 143.70717032, ..., 102.7739301 ,\n",
       "        130.27688366, 138.09909835]),\n",
       " 'threshold_': 717.2417670814343,\n",
       " 'labels_': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " '_mu': 139.62042975692296,\n",
       " '_sigma': 71.51749239129805}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = charts_in_scope[0]\n",
    "print(f'model for chart {chart}:')\n",
    "models[chart].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict in module pyod.models.base:\n",
      "\n",
      "predict(X) method of pyod.models.pca.PCA instance\n",
      "    Predict if a particular sample is an outlier or not.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : numpy array of shape (n_samples, n_features)\n",
      "        The input samples.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    outlier_labels : numpy array of shape (n_samples,)\n",
      "        For each observation, tells whether or not\n",
      "        it should be considered as an outlier according to the\n",
      "        fitted model. 0 stands for inliers and 1 for outliers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(models[chart].predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict_proba in module pyod.models.base:\n",
      "\n",
      "predict_proba(X, method='linear') method of pyod.models.pca.PCA instance\n",
      "    Predict the probability of a sample being outlier. Two approaches\n",
      "    are possible:\n",
      "    \n",
      "    1. simply use Min-max conversion to linearly transform the outlier\n",
      "       scores into the range of [0,1]. The model must be\n",
      "       fitted first.\n",
      "    2. use unifying scores, see :cite:`kriegel2011interpreting`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : numpy array of shape (n_samples, n_features)\n",
      "        The input samples.\n",
      "    \n",
      "    method : str, optional (default='linear')\n",
      "        probability conversion method. It must be one of\n",
      "        'linear' or 'unify'.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    outlier_probability : numpy array of shape (n_samples,)\n",
      "        For each observation, tells whether or not\n",
      "        it should be considered as an outlier according to the\n",
      "        fitted model. Return the outlier probability, ranging\n",
      "        in [0,1].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(models[chart].predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Fit detector. y is ignored in unsupervised methods.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : numpy array of shape (n_samples, n_features)\n",
       "            The input samples.\n",
       "\n",
       "        y : Ignored\n",
       "            Not used, present for API consistency by convention.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        self : object\n",
       "            Fitted estimator.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# validate inputs X and y (optional)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_n_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# PCA is recommended to use on the standardized data (zero mean and\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# unit variance).\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_scalar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn_PCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mwhiten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0msvd_solver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd_solver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0miterated_power\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterated_power\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# copy the attributes from the sklearn PCA object\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# validate the number of components to be used for outlier detection\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcheck_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0minclude_left\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_right\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mparam_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n_selected_components_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# use eigenvalues as the weights of eigenvectors\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweighted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetector_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# outlier scores is the sum of the weighted distances between each\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# sample to the eigenvectors. The eigenvectors with smaller\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# eigenvalues have more influence\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Not all eigenvectors are used, only n_selected_components_ smallest\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# are used since they better reflect the variance change\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                    \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_w_components_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_components_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                                      \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_selected_components_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_scores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_components_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_w_components_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_decision_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\andre\\documents\\repos\\netdata-community\\netdata-agent-api\\netdata-pandas\\venv\\lib\\site-packages\\pyod\\models\\pca.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA.fit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Predict if a particular sample is an outlier or not.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : numpy array of shape (n_samples, n_features)\n",
       "            The input samples.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        outlier_labels : numpy array of shape (n_samples,)\n",
       "            For each observation, tells whether or not\n",
       "            it should be considered as an outlier according to the\n",
       "            fitted model. 0 stands for inliers and 1 for outliers.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'decision_scores_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'threshold_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpred_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_score\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\andre\\documents\\repos\\netdata-community\\netdata-agent-api\\netdata-pandas\\venv\\lib\\site-packages\\pyod\\models\\base.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"Predict raw anomaly score of X using the fitted detector.\n",
       "\n",
       "        The anomaly score of an input sample is computed based on different\n",
       "        detector algorithms. For consistency, outliers are assigned with\n",
       "        larger anomaly scores.\n",
       "\n",
       "        Parameters\n",
       "        ----------\n",
       "        X : numpy array of shape (n_samples, n_features)\n",
       "            The training input samples. Sparse matrices are accepted only\n",
       "            if they are supported by the base estimator.\n",
       "\n",
       "        Returns\n",
       "        -------\n",
       "        anomaly_scores : numpy array of shape (n_samples,)\n",
       "            The anomaly score of the input samples.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'components_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w_components_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_components_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselected_w_components_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\andre\\documents\\repos\\netdata-community\\netdata-agent-api\\netdata-pandas\\venv\\lib\\site-packages\\pyod\\models\\pca.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA.decision_function??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
